{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/8tynsjk14vg7p9s4qx1t_pb00000gn/T/ipykernel_46637/2244548236.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Literal\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import weaviate\n",
    "import weaviate.classes as wvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook is intended to be run after shared_year_eval, as shared_year_eval does some necessary data cleaning.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.connect_to_custom(\n",
    "    http_host=\"localhost\",\n",
    "    http_port=8080,\n",
    "    http_secure=False,\n",
    "    grpc_host=\"localhost\",\n",
    "    grpc_port=50051,\n",
    "    grpc_secure=False,\n",
    "    auth_credentials=weaviate.auth.AuthApiKey(\n",
    "        config[\"AUTHENTICATION_APIKEY_ALLOWED_KEYS\"]\n",
    "    ),  # Set this environment variable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USYD_DOC2VEC_Subject',\n",
       " 'USYD_GLOVE_Subject',\n",
       " 'USYD_INSTRUCTOR_Subject',\n",
       " 'USYD_SBERT_Subject',\n",
       " 'UTS_DOC2VEC_Subject',\n",
       " 'UTS_GLOVE_Subject',\n",
       " 'UTS_INSTRUCTOR_Subject',\n",
       " 'UTS_SBERT_Subject']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections = list(client.collections.list_all().keys())\n",
    "collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that reads json file\n",
    "def read_json(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_keywords = read_json(\"./data/subjects/subject_keywords.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_uts_subjects(\n",
    "    uts_subject_collection,\n",
    "    usyd_subject_vector: dict[str, list[float]],\n",
    "    num_subjects: int = 5,\n",
    "):\n",
    "    response = uts_subject_collection.query.near_vector(\n",
    "        near_vector=usyd_subject_vector,\n",
    "        limit=num_subjects,\n",
    "        return_metadata=wvc.query.MetadataQuery(distance=True),\n",
    "    )\n",
    "    \n",
    "    return [o.properties[\"subjectCode\"] for o in response.objects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_accuracy(num_similar_subjects):\n",
    "    model_accuracy = {}\n",
    "    keyword_overlap_vals = {}\n",
    "\n",
    "    for model in [\"SBERT\", \"INSTRUCTOR\", \"GLOVE\", \"DOC2VEC\"]:\n",
    "        num_subjects = 0\n",
    "        keyword_overlap_sum = 0\n",
    "        keyword_overlap_per_subject = []\n",
    "\n",
    "        usyd_subject_collection = client.collections.get(f\"USYD_{model}_Subject\")\n",
    "        uts_subject_collection = client.collections.get(f\"UTS_{model}_Subject\")\n",
    "\n",
    "        for item in usyd_subject_collection.iterator(include_vector=True):\n",
    "            subject_code = item.properties[\"subjectCode\"]\n",
    "            subject_vector = item.vector\n",
    "\n",
    "            if type(subject_vector) != list:\n",
    "                subject_vector = subject_vector[\"default\"]\n",
    "\n",
    "            similar_uts_subjects = get_similar_uts_subjects(\n",
    "                uts_subject_collection, subject_vector, num_similar_subjects\n",
    "            )\n",
    "            \n",
    "            keyword_overlap = 0\n",
    "            usyd_keywords = subject_keywords[subject_code]\n",
    "\n",
    "            for uts_subject_code in similar_uts_subjects:\n",
    "                uts_keywords = subject_keywords[uts_subject_code]\n",
    "                \n",
    "                keyword_overlap += len(set(uts_keywords).intersection(usyd_keywords)) / 20\n",
    "\n",
    "                num_subjects += 1\n",
    "                \n",
    "            keyword_overlap_per_subject.append(keyword_overlap)\n",
    "            keyword_overlap_sum += keyword_overlap\n",
    "\n",
    "        model_accuracy[model] = keyword_overlap_sum / num_subjects\n",
    "        keyword_overlap_vals[model] = keyword_overlap_per_subject\n",
    "        \n",
    "    return model_accuracy, keyword_overlap_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_model_accuracy_top_2, _ = get_model_accuracy(2)\n",
    "major_model_accuracy_top_5, histogram_data_top_5 = get_model_accuracy(5)\n",
    "major_model_accuracy_top_10, histogram_data_top_10 = get_model_accuracy(10)\n",
    "major_model_accuracy_top_20, histogram_data_top_20 = get_model_accuracy(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert major accuracy to percentage with 4 decimal places\n",
    "major_model_accuracy_top_2 = {k: round(v * 100, 2) for k, v in major_model_accuracy_top_2.items()}\n",
    "major_model_accuracy_top_5 = {k: round(v * 100, 2) for k, v in major_model_accuracy_top_5.items()}\n",
    "major_model_accuracy_top_10 = {k: round(v * 100, 2) for k, v in major_model_accuracy_top_10.items()}\n",
    "major_model_accuracy_top_20 = {k: round(v * 100, 2) for k, v in major_model_accuracy_top_20.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top 2</th>\n",
       "      <th>Top 5</th>\n",
       "      <th>Top 10</th>\n",
       "      <th>Top 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SBERT</th>\n",
       "      <td>12.03</td>\n",
       "      <td>10.91</td>\n",
       "      <td>9.73</td>\n",
       "      <td>8.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSTRUCTOR</th>\n",
       "      <td>14.16</td>\n",
       "      <td>12.01</td>\n",
       "      <td>10.78</td>\n",
       "      <td>9.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLOVE</th>\n",
       "      <td>7.61</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOC2VEC</th>\n",
       "      <td>6.03</td>\n",
       "      <td>5.98</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Top 2  Top 5  Top 10  Top 20\n",
       "SBERT       12.03  10.91    9.73    8.43\n",
       "INSTRUCTOR  14.16  12.01   10.78    9.32\n",
       "GLOVE        7.61   7.51    7.50    7.38\n",
       "DOC2VEC      6.03   5.98    6.00    6.33"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe from the accuracy results\n",
    "major_model_accuracy = pd.DataFrame(\n",
    "    {\n",
    "        \"Top 2\": major_model_accuracy_top_2,\n",
    "        \"Top 5\": major_model_accuracy_top_5,\n",
    "        \"Top 10\": major_model_accuracy_top_10,\n",
    "        \"Top 20\": major_model_accuracy_top_20,\n",
    "    }\n",
    ")\n",
    "major_model_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
